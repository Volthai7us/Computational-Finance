{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_trading(close_price, predicted_change, trade_threshold):\n",
    "    money = 100\n",
    "    coins = 0\n",
    "    for i in range(len(predicted_change) - 1):\n",
    "        if predicted_change[i + 1] > trade_threshold:\n",
    "            coins += money / close_price[i]\n",
    "            money = 0\n",
    "        elif predicted_change[i + 1] < trade_threshold:\n",
    "            money += coins * close_price[i]\n",
    "            coins = 0\n",
    "    return money + coins * close_price[-1]\n",
    "\n",
    "def simulate_holding(test):\n",
    "    money = 100\n",
    "    return (money / test[0]) * test[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_evalute(path='../data/1day.csv', rolling=5, test_size=0.2, trading_threshold=0, plot=False, model=None):\n",
    "    df = pd.read_csv(path)\n",
    "    df.columns = ['open_time', 'open_price', 'high_price', 'low_price', 'close_price', 'volume', 'close_time']\n",
    "    df['open_time'] = pd.to_datetime(df['open_time'] * 1000, unit='ms')\n",
    "    df['close_time'] = pd.to_datetime(df['close_time'], unit='ms')\n",
    "    # df = df[df['open_time'] > '2021-01-01']\n",
    "    close_price_unchanged = df['close_price'].values[:int(test_size * len(df['close_price'].values))]\n",
    "    df['ma'] = df['close_price'].rolling(rolling).mean()\n",
    "    df['change'] = df['close_price'].pct_change() * 100\n",
    "    df['future_change'] = df['change'].shift(-1)\n",
    "\n",
    "    df = df.dropna()\n",
    "    features = ['ma', 'change']\n",
    "    target = 'future_change'\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, shuffle=False)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    # mse = mean_squared_error(y_test, y_pred)\n",
    "    # print(f'Mean Squared Error: {mse}')\n",
    "    if plot:\n",
    "        # start date\n",
    "        start_date = df['open_time'].values[-len(y_pred):][0]\n",
    "        # end date\n",
    "        end_date = df['open_time'].values[-1]\n",
    "        print(f'Start Date: {start_date}')\n",
    "        print(f'End Date: {end_date}')\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plt.plot(y_test.values, label='Actual')\n",
    "        plt.plot(y_pred, label='Predicted')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    close_price = df['close_price'].values[-len(y_pred):]\n",
    "    predicted_change = y_pred\n",
    "    trading_result = simulate_trading(close_price, predicted_change, trading_threshold)\n",
    "    holding_result = simulate_holding(close_price_unchanged)\n",
    "\n",
    "    return trading_result, holding_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.60002028729792\n",
      "207.06345330767243\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(n_estimators=500, max_depth=10, learning_rate=0.01)\n",
    "trading, holding = read_train_evalute(path='../data/1week.csv', model=model, rolling=20, trading_threshold=0, plot=False, test_size=0.1)\n",
    "print(trading)\n",
    "print(holding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_params(path):\n",
    "    lrs = [0.1]\n",
    "    n_estimators = range(140, 240, 20)\n",
    "    max_depth = range(2, 10, 2)\n",
    "    rolling = range(5, 40, 2)\n",
    "\n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "\n",
    "    for lr in lrs:\n",
    "        for n_estimator in n_estimators:\n",
    "            for depth in max_depth:\n",
    "                for roll in rolling:\n",
    "                    model = GradientBoostingRegressor(n_estimators=n_estimator, max_depth=depth, learning_rate=lr)\n",
    "                    trading, _ = read_train_evalute(path=path, model=model, rolling=roll, trading_threshold=0, plot=False, test_size=0.2)\n",
    "                    if trading > best_score:\n",
    "                        best_score = trading\n",
    "                        best_params = (lr, n_estimator, depth, roll)\n",
    "\n",
    "    print(best_score, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179.13965086604225 (0.1, 210, 2, 40)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trading:  179.13965086604225\n",
      "holding:  66.91178582713354\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(n_estimators=210, max_depth=2, learning_rate=0.1)\n",
    "trading, holding = read_train_evalute(path='../data/1week.csv', model=model, rolling=40, trading_threshold=0, plot=False, test_size=0.2)\n",
    "print('trading: ', trading)\n",
    "print('holding: ', holding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m best_path \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m path \u001b[39min\u001b[39;00m best_paths:\n\u001b[0;32m---> 14\u001b[0m     find_best_params(path)\n",
      "Cell \u001b[0;32mIn[81], line 15\u001b[0m, in \u001b[0;36mfind_best_params\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m roll \u001b[39min\u001b[39;00m rolling:\n\u001b[1;32m     14\u001b[0m     model \u001b[39m=\u001b[39m GradientBoostingRegressor(n_estimators\u001b[39m=\u001b[39mn_estimator, max_depth\u001b[39m=\u001b[39mdepth, learning_rate\u001b[39m=\u001b[39mlr)\n\u001b[0;32m---> 15\u001b[0m     trading, _ \u001b[39m=\u001b[39m read_train_evalute(path\u001b[39m=\u001b[39;49mpath, model\u001b[39m=\u001b[39;49mmodel, rolling\u001b[39m=\u001b[39;49mroll, trading_threshold\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, plot\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, test_size\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n\u001b[1;32m     16\u001b[0m     \u001b[39mif\u001b[39;00m trading \u001b[39m>\u001b[39m best_score:\n\u001b[1;32m     17\u001b[0m         best_score \u001b[39m=\u001b[39m trading\n",
      "Cell \u001b[0;32mIn[50], line 18\u001b[0m, in \u001b[0;36mread_train_evalute\u001b[0;34m(path, rolling, test_size, trading_threshold, plot, model)\u001b[0m\n\u001b[1;32m     16\u001b[0m y \u001b[39m=\u001b[39m df[target]\n\u001b[1;32m     17\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39mtest_size, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 18\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     19\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     20\u001b[0m \u001b[39m# mse = mean_squared_error(y_test, y_pred)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m# print(f'Mean Squared Error: {mse}')\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_gb.py:538\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resize_state()\n\u001b[1;32m    537\u001b[0m \u001b[39m# fit the boosting stages\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m n_stages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stages(\n\u001b[1;32m    539\u001b[0m     X,\n\u001b[1;32m    540\u001b[0m     y,\n\u001b[1;32m    541\u001b[0m     raw_predictions,\n\u001b[1;32m    542\u001b[0m     sample_weight,\n\u001b[1;32m    543\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rng,\n\u001b[1;32m    544\u001b[0m     X_val,\n\u001b[1;32m    545\u001b[0m     y_val,\n\u001b[1;32m    546\u001b[0m     sample_weight_val,\n\u001b[1;32m    547\u001b[0m     begin_at_stage,\n\u001b[1;32m    548\u001b[0m     monitor,\n\u001b[1;32m    549\u001b[0m )\n\u001b[1;32m    551\u001b[0m \u001b[39m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \u001b[39mif\u001b[39;00m n_stages \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_gb.py:615\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    608\u001b[0m     old_oob_score \u001b[39m=\u001b[39m loss_(\n\u001b[1;32m    609\u001b[0m         y[\u001b[39m~\u001b[39msample_mask],\n\u001b[1;32m    610\u001b[0m         raw_predictions[\u001b[39m~\u001b[39msample_mask],\n\u001b[1;32m    611\u001b[0m         sample_weight[\u001b[39m~\u001b[39msample_mask],\n\u001b[1;32m    612\u001b[0m     )\n\u001b[1;32m    614\u001b[0m \u001b[39m# fit next stage of trees\u001b[39;00m\n\u001b[0;32m--> 615\u001b[0m raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stage(\n\u001b[1;32m    616\u001b[0m     i,\n\u001b[1;32m    617\u001b[0m     X,\n\u001b[1;32m    618\u001b[0m     y,\n\u001b[1;32m    619\u001b[0m     raw_predictions,\n\u001b[1;32m    620\u001b[0m     sample_weight,\n\u001b[1;32m    621\u001b[0m     sample_mask,\n\u001b[1;32m    622\u001b[0m     random_state,\n\u001b[1;32m    623\u001b[0m     X_csc,\n\u001b[1;32m    624\u001b[0m     X_csr,\n\u001b[1;32m    625\u001b[0m )\n\u001b[1;32m    627\u001b[0m \u001b[39m# track deviance (= loss)\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[39mif\u001b[39;00m do_oob:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_gb.py:257\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    254\u001b[0m     sample_weight \u001b[39m=\u001b[39m sample_weight \u001b[39m*\u001b[39m sample_mask\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m    256\u001b[0m X \u001b[39m=\u001b[39m X_csr \u001b[39mif\u001b[39;00m X_csr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m X\n\u001b[0;32m--> 257\u001b[0m tree\u001b[39m.\u001b[39;49mfit(X, residual, sample_weight\u001b[39m=\u001b[39;49msample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    259\u001b[0m \u001b[39m# update tree leaves\u001b[39;00m\n\u001b[1;32m    260\u001b[0m loss\u001b[39m.\u001b[39mupdate_terminal_regions(\n\u001b[1;32m    261\u001b[0m     tree\u001b[39m.\u001b[39mtree_,\n\u001b[1;32m    262\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m     k\u001b[39m=\u001b[39mk,\n\u001b[1;32m    270\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/tree/_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   1219\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \n\u001b[1;32m   1221\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1247\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   1248\u001b[0m         X,\n\u001b[1;32m   1249\u001b[0m         y,\n\u001b[1;32m   1250\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1251\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m   1252\u001b[0m     )\n\u001b[1;32m   1253\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_paths = [\n",
    "    '../data/1hour.csv',\n",
    "    '../data/2hour.csv',\n",
    "    '../data/4hour.csv',\n",
    "    '../data/1day.csv', #63.22024016325607 (0.1, 200, 2, 5)\n",
    "    '../data/1week.csv', #118.96780905018527 (0.1, 160, 8, 27)\n",
    "    '../data/1month.csv', #158.05054942837288 (0.1, 200, 2, 23)\n",
    "]\n",
    "\n",
    "best_score = 0\n",
    "best_path = None\n",
    "\n",
    "for path in best_paths:\n",
    "    find_best_params(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
